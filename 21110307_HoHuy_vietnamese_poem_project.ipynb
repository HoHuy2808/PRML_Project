{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":7490456,"sourceType":"datasetVersion","datasetId":4361058}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-29T16:22:15.100033Z","iopub.execute_input":"2024-01-29T16:22:15.100599Z","iopub.status.idle":"2024-01-29T16:22:16.896046Z","shell.execute_reply.started":"2024-01-29T16:22:15.100572Z","shell.execute_reply":"2024-01-29T16:22:16.895072Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/vietnamese-poem-dataset/poems_dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2024-01-29T16:22:21.308584Z","iopub.execute_input":"2024-01-29T16:22:21.309418Z","iopub.status.idle":"2024-01-29T16:22:21.313569Z","shell.execute_reply.started":"2024-01-29T16:22:21.309385Z","shell.execute_reply":"2024-01-29T16:22:21.312652Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# !pip install --upgrade pip\n!pip install -q transformers huggingface_hub wandb\n!apt-get install git-lfs","metadata":{"execution":{"iopub.status.busy":"2024-01-29T16:22:23.927848Z","iopub.execute_input":"2024-01-29T16:22:23.928740Z","iopub.status.idle":"2024-01-29T16:22:41.430262Z","shell.execute_reply.started":"2024-01-29T16:22:23.928705Z","shell.execute_reply":"2024-01-29T16:22:41.429258Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\ngit-lfs is already the newest version (3.0.2-1ubuntu0.2).\n0 upgraded, 0 newly installed, 0 to remove and 81 not upgraded.\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T16:23:22.236440Z","iopub.execute_input":"2024-01-29T16:23:22.236941Z","iopub.status.idle":"2024-01-29T16:23:22.567120Z","shell.execute_reply.started":"2024-01-29T16:23:22.236896Z","shell.execute_reply":"2024-01-29T16:23:22.566134Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69ffbdfc07ec47438d4c1292cd18cef4"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Prepare dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom sklearn.model_selection import train_test_split\n\n# Load the CSV file into a DataFrame\ndata = pd.read_csv('/kaggle/input/vietnamese-poem-dataset/poems_dataset.csv')\n\ndef build_text_files(data_df, dest_path):\n    f = open(dest_path, 'w')\n    data = ''\n    for index, row in data_df.iterrows():\n        summary = str(row['content']).strip()\n        summary = re.sub(r\"\\s\", \" \", summary)\n        data += summary + \"  \"\n    f.write(data)\n\n# Split the data into training and test sets\ntrain, test = train_test_split(data, test_size=0.15)\n\n# Write the training set to a text file\nbuild_text_files(train, 'train_dataset.txt')\n\n# Write the test set to a text file\nbuild_text_files(test, 'test_dataset.txt')\n\nprint(\"Train dataset length: \" + str(len(train)))\nprint(\"Test dataset length: \" + str(len(test)))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T16:23:41.407386Z","iopub.execute_input":"2024-01-29T16:23:41.408177Z","iopub.status.idle":"2024-01-29T16:24:05.607133Z","shell.execute_reply.started":"2024-01-29T16:23:41.408142Z","shell.execute_reply":"2024-01-29T16:24:05.606073Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Train dataset length: 145504\nTest dataset length: 25678\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model + Tokenizer\n","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained(\"danghuy1999/gpt2-viwiki\")\nmodel = AutoModelForCausalLM.from_pretrained(\"danghuy1999/gpt2-viwiki\")\n\ntrain_path = 'poem_train.txt'\ntest_path = 'poem_test.txt'","metadata":{"execution":{"iopub.status.busy":"2024-01-29T16:24:08.187457Z","iopub.execute_input":"2024-01-29T16:24:08.188285Z","iopub.status.idle":"2024-01-29T16:24:21.204154Z","shell.execute_reply.started":"2024-01-29T16:24:08.188252Z","shell.execute_reply":"2024-01-29T16:24:21.203388Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/916 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6d921b531e241c6afe85cb4e818b06d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/773k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"109ad455398443a8b2ceb53f131093a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/431k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a0a01a7978143c2bc84af0971360358"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/510M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a84c2aa83374ff784a686921f6b1178"}},"metadata":{}}]},{"cell_type":"code","source":"print(tokenizer.encode(\"<|startoftext|>\")) # fail to encode this token\nprint(tokenizer.encode(\"<|endoftext|>\"))\nprint(tokenizer.encode(\"\"))","metadata":{"execution":{"iopub.status.busy":"2024-01-29T16:24:52.947999Z","iopub.execute_input":"2024-01-29T16:24:52.948936Z","iopub.status.idle":"2024-01-29T16:24:52.965643Z","shell.execute_reply.started":"2024-01-29T16:24:52.948897Z","shell.execute_reply":"2024-01-29T16:24:52.964481Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[28, 92, 1472, 1632, 1247, 19862, 92, 30]\n[0]\n[]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(tokenizer))\ntokenizer.add_tokens([\"\\n\"])\nprint(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-01-29T16:24:57.186089Z","iopub.execute_input":"2024-01-29T16:24:57.186889Z","iopub.status.idle":"2024-01-29T16:24:57.208503Z","shell.execute_reply.started":"2024-01-29T16:24:57.186845Z","shell.execute_reply":"2024-01-29T16:24:57.207529Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"50257\n50258\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-01-29T16:24:59.435661Z","iopub.execute_input":"2024-01-29T16:24:59.436022Z","iopub.status.idle":"2024-01-29T16:24:59.443221Z","shell.execute_reply.started":"2024-01-29T16:24:59.435995Z","shell.execute_reply":"2024-01-29T16:24:59.442330Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"GPT2TokenizerFast(name_or_path='danghuy1999/gpt2-viwiki', vocab_size=50257, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n\t0: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n\t50257: AddedToken(\"\n\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=False),\n}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Resize model's word embedding","metadata":{}},{"cell_type":"code","source":"model.resize_token_embeddings(len(tokenizer))\n\n# New weight for our new tokens (all zeros)\nwith torch.no_grad():\n    model.transformer.wte.weight[-1, :] = torch.zeros([768])\n\nprint(model.transformer.wte.weight.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T16:25:01.926169Z","iopub.execute_input":"2024-01-29T16:25:01.926569Z","iopub.status.idle":"2024-01-29T16:25:02.530720Z","shell.execute_reply.started":"2024-01-29T16:25:01.926526Z","shell.execute_reply":"2024-01-29T16:25:02.529710Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"torch.Size([50258, 768])\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TextDataset,DataCollatorForLanguageModeling\n\ndef load_dataset(train_path,test_path,tokenizer):\n    train_dataset = TextDataset(\n          tokenizer=tokenizer,\n          file_path=train_path,\n          block_size=100)\n     \n    test_dataset = TextDataset(\n          tokenizer=tokenizer,\n          file_path=test_path,\n          block_size=100)   \n    \n    data_collator = DataCollatorForLanguageModeling(\n        tokenizer=tokenizer, mlm=False,\n    )\n    return train_dataset,test_dataset,data_collator\ntrain_path = '/kaggle/working/train_dataset.txt'\ntest_path =  '/kaggle/working/test_dataset.txt'\ntrain_dataset,test_dataset,data_collator = load_dataset(train_path,test_path,tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T16:25:11.331185Z","iopub.execute_input":"2024-01-29T16:25:11.331909Z","iopub.status.idle":"2024-01-29T16:27:39.027955Z","shell.execute_reply.started":"2024-01-29T16:25:11.331877Z","shell.execute_reply":"2024-01-29T16:27:39.027100Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Initialize Trainer with TrainingArguments and GPT-2 model","metadata":{}},{"cell_type":"code","source":"%env WANDB_PROJECT=GPT2-POEM\n%env WANDB_WATCH=all","metadata":{"execution":{"iopub.status.busy":"2024-01-29T16:28:04.341721Z","iopub.execute_input":"2024-01-29T16:28:04.342707Z","iopub.status.idle":"2024-01-29T16:28:04.348400Z","shell.execute_reply.started":"2024-01-29T16:28:04.342674Z","shell.execute_reply":"2024-01-29T16:28:04.347436Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"env: WANDB_PROJECT=GPT2-POEM\nenv: WANDB_WATCH=all\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.makedirs('/kaggle/working/GPT2_Poet')","metadata":{"execution":{"iopub.status.busy":"2024-01-29T16:28:06.846480Z","iopub.execute_input":"2024-01-29T16:28:06.847357Z","iopub.status.idle":"2024-01-29T16:28:06.853182Z","shell.execute_reply.started":"2024-01-29T16:28:06.847325Z","shell.execute_reply":"2024-01-29T16:28:06.850879Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import wandb\nfrom transformers import TrainerCallback\nfrom transformers import Trainer, TrainingArguments,AutoModelWithLMHead,EarlyStoppingCallback\n\nclass StopTrainingCallback(TrainerCallback):\n    def on_step_end(self, args, state, control, **kwargs):\n        if state.global_step > 1500:\n            control.should_training_stop = True\n\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/GPT2_Poet\",\n    overwrite_output_dir=True, #overwrite the content of the output directory\n    num_train_epochs= 5,\n    per_device_train_batch_size= 32,\n    per_device_eval_batch_size= 32,\n    evaluation_strategy = 'steps',\n    eval_steps = 500, # Number of update steps between two evaluations.\n    save_strategy = 'steps',\n    push_to_hub=True,\n    hub_model_id = \"GPT2_Poet\",\n    save_total_limit = 10,\n    warmup_steps = 1000,\n    report_to=                      'wandb',\n    run_name=                       'Run 6 - w/o label smoothing',\n    logging_steps =                 5,                    \n    gradient_accumulation_steps=    2,\n    learning_rate=                  5e-4,\n    weight_decay =                  0.5,\n    dataloader_num_workers = 2,\n    # label_smoothing_factor = 0.3,\n    load_best_model_at_end = True,\n    metric_for_best_model = 'eval_loss',\n\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    callbacks = [EarlyStoppingCallback(early_stopping_patience= 5),StopTrainingCallback()]\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T16:28:09.104686Z","iopub.execute_input":"2024-01-29T16:28:09.105039Z","iopub.status.idle":"2024-01-29T16:28:11.166414Z","shell.execute_reply.started":"2024-01-29T16:28:09.105011Z","shell.execute_reply":"2024-01-29T16:28:11.165629Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T16:28:14.629876Z","iopub.execute_input":"2024-01-29T16:28:14.630623Z","iopub.status.idle":"2024-01-29T17:34:27.726060Z","shell.execute_reply.started":"2024-01-29T16:28:14.630586Z","shell.execute_reply":"2024-01-29T17:34:27.724819Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240129_162828-46oc0aqb</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/hohuy-work/GPT2-POEM/runs/46oc0aqb' target=\"_blank\">Run 6 - w/o label smoothing</a></strong> to <a href='https://wandb.ai/hohuy-work/GPT2-POEM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/hohuy-work/GPT2-POEM' target=\"_blank\">https://wandb.ai/hohuy-work/GPT2-POEM</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/hohuy-work/GPT2-POEM/runs/46oc0aqb' target=\"_blank\">https://wandb.ai/hohuy-work/GPT2-POEM/runs/46oc0aqb</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1501' max='6405' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1501/6405 1:05:11 < 3:33:17, 0.38 it/s, Epoch 1/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>5.660500</td>\n      <td>5.524101</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>5.107700</td>\n      <td>5.046876</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>4.841400</td>\n      <td>4.758120</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nThere were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1501, training_loss=5.545836874995527, metrics={'train_runtime': 3961.1211, 'train_samples_per_second': 207.044, 'train_steps_per_second': 1.617, 'total_flos': 9804626265600000.0, 'train_loss': 5.545836874995527, 'epoch': 1.17})"},"metadata":{}}]},{"cell_type":"code","source":"model.push_to_hub('GPT2_Poet')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.push_to_hub('GPT2_Poet')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test the model","metadata":{}},{"cell_type":"code","source":"import torch\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:34:57.270860Z","iopub.execute_input":"2024-01-29T17:34:57.271240Z","iopub.status.idle":"2024-01-29T17:34:57.278151Z","shell.execute_reply.started":"2024-01-29T17:34:57.271204Z","shell.execute_reply":"2024-01-29T17:34:57.277031Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntokenizer = AutoTokenizer.from_pretrained(\"tuanle/GPT2_Poet\")\nmodel = AutoModelForCausalLM.from_pretrained(\"tuanle/GPT2_Poet\").to(device)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:35:18.406218Z","iopub.execute_input":"2024-01-29T17:35:18.406960Z","iopub.status.idle":"2024-01-29T17:35:23.029098Z","shell.execute_reply.started":"2024-01-29T17:35:18.406929Z","shell.execute_reply":"2024-01-29T17:35:23.027991Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/589 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33ff33bfeccf4744aca4cb8f11c3158d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/773k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86ecfbf599e84cdbb9b36da6e2c599a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/431k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1ac889205e642cbae9bdda288631392"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43c2a5995cee4057a9ec9a6bf30d9757"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/13.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a539801ac6e14812ad93ded7847792d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32a71cb68cf84088a2f1493c6d659e77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30f0c18777ae4fe88c689c44cc49d359"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/510M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0558a2926e044626b223bdb0a730b67d"}},"metadata":{}}]},{"cell_type":"code","source":"text = \"h√¥m nay\"\n\ninput_ids = tokenizer.encode(text, return_tensors='pt').to(device)\nmin_length = 60\nmax_length = 100\n\nsample_outputs = model.generate(input_ids,pad_token_id=tokenizer.eos_token_id,\n                                   do_sample=True,\n                                   max_length=max_length,\n                                   min_length=min_length,\n                                   top_p = 0.8,\n                                   num_beams= 10,\n                                   no_repeat_ngram_size= 2,\n                                   num_return_sequences= 3)\n\nfor i, sample_output in enumerate(sample_outputs):\n    print(\">> Generated text {}\\n\\n{}\".format(i+1, tokenizer.decode(sample_output.tolist(), skip_special_tokens=True)))\n    print('\\n---')","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:38:00.300095Z","iopub.execute_input":"2024-01-29T17:38:00.300456Z","iopub.status.idle":"2024-01-29T17:38:02.431029Z","shell.execute_reply.started":"2024-01-29T17:38:00.300428Z","shell.execute_reply":"2024-01-29T17:38:02.429862Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":">> Generated text 1\n\nh√¥m nay tr·ªùi ƒë√£ sang ƒë√¥ng\nnh·ªõ m√πa thu ƒë·∫øn b√™n c·∫ßu ƒë·ª£i ch·ªù\nƒë√™m thu hoa n·ªü b√™n ƒë∆∞·ªùng\nm√™nh m√¥ng s√≥ng v·ªó m√™nh m√¥ng c√µi l√≤ng\nv·∫ßn th∆° l·ª•c b√°t th·∫´n th·ªù\nm√† nghe ti·∫øng s√°o vi vu l·ªùi ca\nh·ªèi r·∫±ng ai ·ªü ƒë√¢u ƒë√¢y\nth∆∞a r·∫±ng ta ·ªü ƒë√¢y ƒë√¢y ƒë√¢u m√†\nm·ªôt m√¨nh m·ªôt b√≥ng trƒÉng v√†ng\nng∆∞·ªùi ta g·∫∑p g·ª° m·ªôt m√¨nh g·∫∑p nhau\nc·ªõ sao g·∫∑p l·∫°i m·ªôt ng∆∞·ªùi\nƒë·ªÉ cho ai l·∫°i g·∫∑p\n\n---\n>> Generated text 2\n\nh√¥m nay tr·ªùi ƒë√£ sang ƒë√¥ng\nnh·ªõ m√πa thu ƒë·∫øn b√™n c·∫ßu ƒë·ª£i ch·ªù\nƒë√™m thu hoa n·ªü b√™n ƒë∆∞·ªùng\nm√™nh m√¥ng s√≥ng v·ªó m√™nh m√¥ng c√µi l√≤ng\nv·∫ßn th∆° l·ª•c b√°t th·∫´n th·ªù\nm√† nghe ti·∫øng s√°o vi vu l·ªùi ca\nh·ªèi r·∫±ng ai ·ªü ƒë√¢u ƒë√¢y\nth∆∞a r·∫±ng ta ·ªü ƒë√¢y ƒë√¢y ƒë√¢u m√†\nm·ªôt m√¨nh m·ªôt b√≥ng trƒÉng v√†ng\nng∆∞·ªùi ta g·∫∑p g·ª° m·ªôt m√¨nh g·∫∑p nhau\nc·ªõ sao g·∫∑p l·∫°i m·ªôt ng∆∞·ªùi\nƒë·ªÉ cho m√¨nh l·∫°i g·∫∑p\n\n---\n>> Generated text 3\n\nh√¥m nay tr·ªùi ƒë√£ sang ƒë√¥ng\nnh·ªõ m√πa thu ƒë·∫øn b√™n c·∫ßu ƒë·ª£i ch·ªù\nƒë√™m thu hoa n·ªü b√™n ƒë∆∞·ªùng\nm√™nh m√¥ng s√≥ng v·ªó m√™nh m√¥ng c√µi l√≤ng\nv·∫ßn th∆° l·ª•c b√°t th·∫´n th·ªù\nm√† nghe ti·∫øng s√°o vi vu l·ªùi ca\nh·ªèi r·∫±ng ai ·ªü ƒë√¢u ƒë√¢y\nth∆∞a r·∫±ng ta ·ªü ƒë√¢y ƒë√¢y ƒë√¢u m√†\nm·ªôt m√¨nh m·ªôt b√≥ng trƒÉng v√†ng\nng∆∞·ªùi ta g·∫∑p g·ª° m·ªôt m√¨nh g·∫∑p nhau\nc·ªõ sao g·∫∑p l·∫°i m·ªôt ng∆∞·ªùi\nƒë·ªÉ cho ai g·∫∑p m·ªôt\n\n---\n","output_type":"stream"}]}]}